import json
import re
from pathlib import Path
from typing import Any, Dict, Optional
from pydantic import Field

import httpx

from backend.tools.base_tool import BaseTool, ToolContext
from backend.tools.built_in.knowledge_tools import KnowledgeSynthesisTool

class OpenAPIBridgeTool(BaseTool):
    """
    Ingests an OpenAPI/Swagger URL or JSON specification, automatically generates a Python HTTPX client class for it, and saves it to the Knowledge Graph so it can be used by the swarm going forward.
    This allows the agent to integrate with ANY external application without human-written connectors.
    """
    
    openapi_url: str = Field(..., description="The URL to the OpenAPI/Swagger JSON/YAML specification file.")
    service_name: str = Field(..., description="Short name of the service (e.g. 'stripe', 'jira', 'salesforce'). Used for class naming.")

    async def run(self, context: Optional[ToolContext] = None, **kwargs) -> Any:
        openapi_url = self.openapi_url
        service_name = self.service_name
        
        if not openapi_url or not service_name:
            return {"error": "Both openapi_url and service_name are required."}
            
        try:
            import yaml
            # 1. Fetch the specification
            async with httpx.AsyncClient() as client:
                response = await client.get(openapi_url)
                if response.status_code != 200:
                    return {"error": f"Failed to fetch OpenAPI spec. HTTP {response.status_code}"}
                
                # Check if it's JSON or YAML
                content_type = response.headers.get("Content-Type", "").lower()
                is_yaml = "yaml" in content_type or openapi_url.endswith(".yaml") or openapi_url.endswith(".yml")
                
                try:
                    if not is_yaml:
                         spec = response.json()
                    else:
                         spec = yaml.safe_load(response.text)
                except Exception as parse_e:
                     # Fallback strategy
                     try:
                         spec = yaml.safe_load(response.text)
                     except Exception:
                         return {"error": f"Failed to parse OpenAPI spec as either JSON or YAML: {str(parse_e)}"}
                         
        except Exception as e:
            return {"error": f"Failed to fetch OpenAPI spec from {openapi_url}: {str(e)}"}
            
        # 2. Extract Base URL and Metadata
        title = spec.get("info", {}).get("title", service_name)
        servers = spec.get("servers", [])
        base_url = servers[0]["url"] if servers else f"https://api.{service_name.lower()}.com"
        
        try:
            import tempfile
            import subprocess
            import os
            
            # Save spec to a temp file
            with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as tmp_spec:
                json.dump(spec, tmp_spec)
                tmp_spec_path = tmp_spec.name
                
            # Run datamodel-code-generator
            cmd = [
                "datamodel-codegen",
                "--input", tmp_spec_path,
                "--input-file-type", "openapi",
                "--output-model-type", "pydantic_v2.BaseModel",
                "--target-python-version", "3.10",
                "--openapi-scopes", "paths"
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode != 0:
                os.unlink(tmp_spec_path)
                return {"error": f"Failed to generate Pydantic models: {result.stderr}"}
                
            pydantic_models_code = result.stdout
            os.unlink(tmp_spec_path)
            
        except Exception as e:
            return {"error": f"Error running datamodel-code-generator: {e}"}
            
        # 3. Generate a dynamic Python HTTPX Client wrapper around the Pydantic models
        paths = spec.get("paths", {})
        class_name = "".join(word.capitalize() for word in service_name.split("_")) + "Client"
        
        py_code = f"\"\"\"\nAutogenerated Pydantic Models and HTTPX Client for {title}\n\"\"\"\n\n"
        py_code += "import httpx\n"
        py_code += "from typing import Dict, Any, Optional, List, Union\n"
        py_code += "from pydantic import BaseModel, Field, RootModel\n\n"
        
        # Inject the generated Pydantic models (removing their redundant imports)
        clean_models = pydantic_models_code.replace("from __future__ import annotations", "")
        clean_models = re.sub(r'from typing import .*', '', clean_models)
        clean_models = re.sub(r'from pydantic import .*', '', clean_models)
        py_code += clean_models.strip() + "\n\n"
        
        # Inject the Client Class
        py_code += f'class {class_name}:\n'
        py_code += f'    """Autogenerated Client for {title}"""\n\n'
        py_code += f'    def __init__(self, api_key: str = "", base_url: str = "{base_url}"):\n'
        py_code += f'        self.base_url = base_url.rstrip("/")\n'
        py_code += f'        self.headers = {{"Authorization": f"Bearer {{api_key}}", "Content-Type": "application/json"}} if api_key else {{}}\n\n'
        
        method_count = 0
        for path, operations in paths.items():
            for method, op_details in operations.items():
                if method.lower() not in ["get", "post", "put", "delete", "patch"]:
                    continue
                    
                op_id = op_details.get("operationId")
                if not op_id:
                    clean_path = re.sub(r'[{|}]', '', path).strip("/").replace("/", "_")
                    op_id = f"{method.lower()}_{clean_path}"
                
                func_name = re.sub(r'[^a-zA-Z0-9_]', '_', op_id).lower()
                
                py_code += f'    def {func_name}(self, path_params: Dict[str, Any] = None, data: Dict[str, Any] = None, params: Dict[str, Any] = None) -> httpx.Response:\n'
                py_code += f'        """\n'
                py_code += f'        {op_details.get("summary", "No summary")}\n'
                py_code += f'        """\n'
                py_code += f'        url = self.base_url + "{path}"\n'
                py_code += f'        if path_params:\n'
                py_code += f'            for k, v in path_params.items():\n'
                py_code += f'                url = url.replace("{"{"}k{"}"}", str(v))\n\n'
                py_code += f'        with httpx.Client() as client:\n'
                py_code += f'            return client.request(\n'
                py_code += f'                method="{method.upper()}",\n'
                py_code += f'                url=url,\n'
                py_code += f'                json=data,\n'
                py_code += f'                params=params,\n'
                py_code += f'                headers=self.headers\n'
                py_code += f'            )\n\n'
                method_count += 1
                
                if method_count >= 50:
                    break
            if method_count >= 50:
                break
                
        # 4. Save via KnowledgeSynthesisTool to persist it for the Swarm
        kr_context = f"Autogenerated API client for {title} (OpenAPI ingestion).\n\n"
        kr_context += f"Base URL: {base_url}\n"
        kr_context += f"Total endpoints parsed: {method_count}\n"
        kr_context += f"Pydantic schemas automatically generated via `datamodel-code-generator`.\n"
        
        kr_solution = f"To interact with {service_name}, create an instance of `{class_name}` and call its endpoints.\n\n"
        kr_solution += f"The module includes full Pydantic models for request/response serialization.\n\n"
        kr_solution += f"```python\n{py_code}\n```\n"

        # Instantiate the Knowledge Tool and run it directly
        knowledge_tool = KnowledgeSynthesisTool(
            title=f"{class_name}_Integration",
            description=f"Runnable Python Client for the {title} generated from OpenAPI spec.",
            context=kr_context,
            solution_steps=kr_solution,
            tags=[service_name.lower(), "openapi", "integration", "autogenerated", "pydantic"]
        )
        # Note: BaseTool run() takes 'context' as ToolContext, but the Pydantic model ALSO has 'context' as a string field.
        # This is a collision. We must pass ToolContext via run() and let the model retain its str context.
        result = await knowledge_tool.run(context=context)
        
        return {
            "status": "success",
            "message": f"Successfully generated {class_name} with {method_count} endpoints using strict Pydantic schemas.",
            "knowledge_unit": result,
            "preview_code": py_code[:1800] + "\n...[truncated]"
        }
